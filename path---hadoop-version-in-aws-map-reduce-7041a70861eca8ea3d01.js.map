{"version":3,"sources":["webpack:///path---hadoop-version-in-aws-map-reduce-7041a70861eca8ea3d01.js","webpack:///./.cache/json/hadoop-version-in-aws-map-reduce.json"],"names":["webpackJsonp","865","module","exports","data","post","id","html","htmlAst","type","children","tagName","properties","value","quirksMode","fields","slug","prefix","frontmatter","title","subTitle","cover","author","footnote","site","siteMetadata","facebook","appId","pathContext"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,MAAQC,GAAA,uIAAAC,KAAA,08BAAulCC,SAAiBC,KAAA,OAAAC,WAA2BD,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,kQAAwRJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,+GAAqIJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,8UAAoWJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,oJAA0KJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,4GAAgIT,MAAUU,YAAA,IAAoBC,QAAWC,KAAA,qCAAAC,OAAA,cAAkEC,aAAgBC,MAAA,mCAAAC,SAAA,8DAAAC,MAAA,OAAkIC,QAAWhB,GAAA,2FAAAC,KAAA,oLAA0RgB,UAAajB,GAAA,6FAAAC,KAAA,wEAAgLiB,MAASC,cAAgBC,UAAYC,MAAA,OAAcC,aAAgBZ,KAAA","file":"path---hadoop-version-in-aws-map-reduce-7041a70861eca8ea3d01.js","sourcesContent":["webpackJsonp([32012598179034],{\n\n/***/ 865:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"post\":{\"id\":\"/Users/prasanna/projects/blog/content/posts/2010-11-15--hadoop-version-in-aws-map-reduce/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p>Creating job flows using AWS MapReduce‚Äôs GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.</p>\\n<p>java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V</p>\\n<p>I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn‚Äôt face this issue when i did it through GUI.</p>\\n<p>As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.</p>\\n<p>JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(‚Äú0.20‚Äù);</p>\",\"htmlAst\":{\"type\":\"root\",\"children\":[{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"Creating job flows using AWS MapReduce‚Äôs GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn‚Äôt face this issue when i did it through GUI.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(‚Äú0.20‚Äù);\"}]}],\"data\":{\"quirksMode\":false}},\"fields\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\",\"prefix\":\"2010-11-15\"},\"frontmatter\":{\"title\":\"Hadoop Version in AWS Map Reduce\",\"subTitle\":\"Performing Map Reduce operation using Amazon AWS interface.\",\"cover\":null}},\"author\":{\"id\":\"/Users/prasanna/projects/blog/content/parts/author.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><strong>Prasanna</strong> is a full stack web developer, loves to build user interfaces with Javascript. Considers himself as a geek, quick learner and a team player üòÉ </p>\"},\"footnote\":{\"id\":\"/Users/prasanna/projects/blog/content/parts/footnote.md absPath of file >>> MarkdownRemark\",\"html\":\"<ul>\\n<li>rants and writings through personal experience</li>\\n</ul>\"},\"site\":{\"siteMetadata\":{\"facebook\":{\"appId\":\"\"}}}},\"pathContext\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---hadoop-version-in-aws-map-reduce-7041a70861eca8ea3d01.js","module.exports = {\"data\":{\"post\":{\"id\":\"/Users/prasanna/projects/blog/content/posts/2010-11-15--hadoop-version-in-aws-map-reduce/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p>Creating job flows using AWS MapReduce‚Äôs GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.</p>\\n<p>java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V</p>\\n<p>I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn‚Äôt face this issue when i did it through GUI.</p>\\n<p>As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.</p>\\n<p>JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(‚Äú0.20‚Äù);</p>\",\"htmlAst\":{\"type\":\"root\",\"children\":[{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"Creating job flows using AWS MapReduce‚Äôs GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn‚Äôt face this issue when i did it through GUI.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(‚Äú0.20‚Äù);\"}]}],\"data\":{\"quirksMode\":false}},\"fields\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\",\"prefix\":\"2010-11-15\"},\"frontmatter\":{\"title\":\"Hadoop Version in AWS Map Reduce\",\"subTitle\":\"Performing Map Reduce operation using Amazon AWS interface.\",\"cover\":null}},\"author\":{\"id\":\"/Users/prasanna/projects/blog/content/parts/author.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><strong>Prasanna</strong> is a full stack web developer, loves to build user interfaces with Javascript. Considers himself as a geek, quick learner and a team player üòÉ </p>\"},\"footnote\":{\"id\":\"/Users/prasanna/projects/blog/content/parts/footnote.md absPath of file >>> MarkdownRemark\",\"html\":\"<ul>\\n<li>rants and writings through personal experience</li>\\n</ul>\"},\"site\":{\"siteMetadata\":{\"facebook\":{\"appId\":\"\"}}}},\"pathContext\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/hadoop-version-in-aws-map-reduce.json\n// module id = 865\n// module chunks = 32012598179034"],"sourceRoot":""}