{"version":3,"sources":["webpack:///path---hadoop-version-in-aws-map-reduce-b75390728808b1db6ae5.js","webpack:///./.cache/json/hadoop-version-in-aws-map-reduce.json"],"names":["webpackJsonp","867","module","exports","data","post","id","html","htmlAst","type","children","tagName","properties","value","quirksMode","fields","slug","prefix","frontmatter","title","subTitle","cover","draft","author","footnote","site","siteMetadata","facebook","appId","pathContext"],"mappings":"AAAAA,cAAc,iBAERC,IACA,SAAUC,EAAQC,GCHxBD,EAAAC,SAAkBC,MAAQC,MAAQC,GAAA,qIAAAC,KAAA,08BAAqlCC,SAAiBC,KAAA,OAAAC,WAA2BD,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,kQAAwRJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,+GAAqIJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,8UAAoWJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,oJAA0KJ,KAAA,OAAAI,MAAA,OAA6BJ,KAAA,UAAAE,QAAA,IAAAC,cAA8CF,WAAcD,KAAA,OAAAI,MAAA,4GAAgIT,MAAUU,YAAA,IAAoBC,QAAWC,KAAA,qCAAAC,OAAA,cAAkEC,aAAgBC,MAAA,mCAAAC,SAAA,8DAAAC,MAAA,KAAAC,MAAA,OAA+IC,QAAWjB,GAAA,yFAAAC,KAAA,wJAA4PiB,UAAalB,GAAA,2FAAAC,KAAA,wEAA8KkB,MAASC,cAAgBC,UAAYC,MAAA,uBAA8BC,aAAgBb,KAAA","file":"path---hadoop-version-in-aws-map-reduce-b75390728808b1db6ae5.js","sourcesContent":["webpackJsonp([32012598179034],{\n\n/***/ 867:\n/***/ (function(module, exports) {\n\n\tmodule.exports = {\"data\":{\"post\":{\"id\":\"/home/runner/work/blog/blog/content/posts/2010-11-15--hadoop-version-in-aws-map-reduce/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p>Creating job flows using AWS MapReduce’s GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.</p>\\n<p>java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V</p>\\n<p>I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn’t face this issue when i did it through GUI.</p>\\n<p>As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.</p>\\n<p>JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(“0.20”);</p>\",\"htmlAst\":{\"type\":\"root\",\"children\":[{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"Creating job flows using AWS MapReduce’s GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn’t face this issue when i did it through GUI.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(“0.20”);\"}]}],\"data\":{\"quirksMode\":false}},\"fields\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\",\"prefix\":\"2010-11-15\"},\"frontmatter\":{\"title\":\"Hadoop Version in AWS Map Reduce\",\"subTitle\":\"Performing Map Reduce operation using Amazon AWS interface.\",\"cover\":null,\"draft\":null}},\"author\":{\"id\":\"/home/runner/work/blog/blog/content/parts/author.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><strong>Prasanna</strong> is a full stack web developer, with loads of experience in architecting and coding enterprise software solutions.  </p>\"},\"footnote\":{\"id\":\"/home/runner/work/blog/blog/content/parts/footnote.md absPath of file >>> MarkdownRemark\",\"html\":\"<ul>\\n<li>rants and writings through personal experience</li>\\n</ul>\"},\"site\":{\"siteMetadata\":{\"facebook\":{\"appId\":\"670156599751120%\"}}}},\"pathContext\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\"}}\n\n/***/ })\n\n});\n\n\n// WEBPACK FOOTER //\n// path---hadoop-version-in-aws-map-reduce-b75390728808b1db6ae5.js","module.exports = {\"data\":{\"post\":{\"id\":\"/home/runner/work/blog/blog/content/posts/2010-11-15--hadoop-version-in-aws-map-reduce/index.md absPath of file >>> MarkdownRemark\",\"html\":\"<p>Creating job flows using AWS MapReduce’s GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.</p>\\n<p>java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V</p>\\n<p>I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn’t face this issue when i did it through GUI.</p>\\n<p>As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.</p>\\n<p>JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(“0.20”);</p>\",\"htmlAst\":{\"type\":\"root\",\"children\":[{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"Creating job flows using AWS MapReduce’s GUI is pretty simple and very straight forward. But i wanted to use Java SDK to create/run jobs in MapReduce. I could successfully able set up the job and configured all the parameters except for a weird error.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"java.lang.NoSuchMethodError:\\norg.apache.hadoop.mapred.JobConf.\\nsetBooleanIfUnset(Ljava/lang/String;Z)V\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"I was constantly getting this error while running the job. Initially i had no idea why this error occurs and none of the forum talks about it either. Then i figured out that the default Hadoop version used by the Ec2 instances was 0.18 and i was expecting 0.20. Interestingly i didn’t face this issue when i did it through GUI.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"As a solution i need to explicitly set the version number as 0.20 to the Instances object so that it will use the same while running the job.\"}]},{\"type\":\"text\",\"value\":\"\\n\"},{\"type\":\"element\",\"tagName\":\"p\",\"properties\":{},\"children\":[{\"type\":\"text\",\"value\":\"JobFlowInstancesConfig instances = new JobFlowInstancesConfig();\\ninstances.setHadoopVersion(“0.20”);\"}]}],\"data\":{\"quirksMode\":false}},\"fields\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\",\"prefix\":\"2010-11-15\"},\"frontmatter\":{\"title\":\"Hadoop Version in AWS Map Reduce\",\"subTitle\":\"Performing Map Reduce operation using Amazon AWS interface.\",\"cover\":null,\"draft\":null}},\"author\":{\"id\":\"/home/runner/work/blog/blog/content/parts/author.md absPath of file >>> MarkdownRemark\",\"html\":\"<p><strong>Prasanna</strong> is a full stack web developer, with loads of experience in architecting and coding enterprise software solutions.  </p>\"},\"footnote\":{\"id\":\"/home/runner/work/blog/blog/content/parts/footnote.md absPath of file >>> MarkdownRemark\",\"html\":\"<ul>\\n<li>rants and writings through personal experience</li>\\n</ul>\"},\"site\":{\"siteMetadata\":{\"facebook\":{\"appId\":\"670156599751120%\"}}}},\"pathContext\":{\"slug\":\"/hadoop-version-in-aws-map-reduce/\"}}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/json-loader!./.cache/json/hadoop-version-in-aws-map-reduce.json\n// module id = 867\n// module chunks = 32012598179034"],"sourceRoot":""}